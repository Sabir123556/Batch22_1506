{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3AR+Reo8804xqa9Ui0NEI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabir123556/Batch22_1506/blob/main/project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5lkaZGGeU7O",
        "outputId": "36e3cc20-038b-4555-fcb9-90d946b94456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded. Shape: (1218, 11)\n",
            "Columns: ['Company Names', 'Cars Names', 'Engines', 'CC/Battery Capacity', 'HorsePower', 'Total Speed', 'Performance(0 - 100 )KM/H', 'Cars Prices', 'Fuel Types', 'Seats', 'Torque']\n",
            "Detected price column: Cars Names\n",
            "\n",
            "Auto-detected column mapping:\n",
            "  company: Company Names\n",
            "  car_name: Cars Names\n",
            "  engine_type: Engines\n",
            "  capacity: CC/Battery Capacity\n",
            "  horsepower: HorsePower\n",
            "  torque: Torque\n",
            "  top_speed: Performance(0 - 100 )KM/H\n",
            "  acceleration: None\n",
            "  fuel_type: Fuel Types\n",
            "  seating: Seats\n",
            "\n",
            "Working dataframe columns after rename: ['company', 'engine_type', 'capacity', 'horsepower', 'torque', 'top_speed', 'fuel_type', 'seating', 'price']\n",
            "\n",
            "Dropped 793 rows without parsable price. Remaining: 425\n",
            "\n",
            "Categorical features: ['company', 'engine_type', 'fuel_type']\n",
            "Numeric features: ['capacity_num', 'hp_num', 'torque_num', 'topspeed_num', 'accel_num', 'seating_num']\n",
            "\n",
            "Target price stats (num):\n",
            "count         425.00\n",
            "mean       622775.81\n",
            "std       4212965.42\n",
            "min             1.00\n",
            "25%             8.00\n",
            "50%           350.00\n",
            "75%          2008.00\n",
            "max      45750000.00\n",
            "Name: price_num, dtype: object\n",
            "\n",
            "=== REGRESSION: Training and evaluating models ===\n",
            "  ERROR training LinearRegression: got an unexpected keyword argument 'squared'\n",
            "  ERROR training Ridge: got an unexpected keyword argument 'squared'\n",
            "  ERROR training Lasso: got an unexpected keyword argument 'squared'\n",
            "  ERROR training SVR: got an unexpected keyword argument 'squared'\n",
            "  ERROR training KNNRegressor: got an unexpected keyword argument 'squared'\n",
            "  ERROR training DecisionTreeRegressor: got an unexpected keyword argument 'squared'\n",
            "  ERROR training RandomForestRegressor: got an unexpected keyword argument 'squared'\n",
            "  ERROR training GradientBoostingRegressor: got an unexpected keyword argument 'squared'\n",
            "\n",
            "Price bin edges (numeric): [1.000e+00 8.000e+00 3.500e+02 2.008e+03 4.575e+07]\n",
            "\n",
            "Price bin counts:\n",
            "price_bin\n",
            "Bin_1    111\n",
            "Bin_4    106\n",
            "Bin_2    105\n",
            "Bin_3    103\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== CLASSIFICATION: Training and printing classification reports ===\n",
            "\n",
            "LogisticRegression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Bin_1     0.6250    0.9091    0.7407        22\n",
            "       Bin_2     0.5263    0.4762    0.5000        21\n",
            "       Bin_3     0.6875    0.5238    0.5946        21\n",
            "       Bin_4     0.5000    0.4286    0.4615        21\n",
            "\n",
            "    accuracy                         0.5882        85\n",
            "   macro avg     0.5847    0.5844    0.5742        85\n",
            "weighted avg     0.5852    0.5882    0.5762        85\n",
            "\n",
            "Confusion Matrix (rows=truth, cols=pred) shape (4, 4)\n",
            "\n",
            "DecisionTree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Bin_1     0.5143    0.8182    0.6316        22\n",
            "       Bin_2     0.5238    0.5238    0.5238        21\n",
            "       Bin_3     0.7000    0.3333    0.4516        21\n",
            "       Bin_4     0.4737    0.4286    0.4500        21\n",
            "\n",
            "    accuracy                         0.5294        85\n",
            "   macro avg     0.5529    0.5260    0.5143        85\n",
            "weighted avg     0.5525    0.5294    0.5156        85\n",
            "\n",
            "Confusion Matrix (rows=truth, cols=pred) shape (4, 4)\n",
            "\n",
            "RandomForest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Bin_1     0.5484    0.7727    0.6415        22\n",
            "       Bin_2     0.5600    0.6667    0.6087        21\n",
            "       Bin_3     0.7333    0.5238    0.6111        21\n",
            "       Bin_4     0.7143    0.4762    0.5714        21\n",
            "\n",
            "    accuracy                         0.6118        85\n",
            "   macro avg     0.6390    0.6098    0.6082        85\n",
            "weighted avg     0.6379    0.6118    0.6086        85\n",
            "\n",
            "Confusion Matrix (rows=truth, cols=pred) shape (4, 4)\n",
            "\n",
            "GradientBoosting Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Bin_1     0.6071    0.7727    0.6800        22\n",
            "       Bin_2     0.6000    0.5714    0.5854        21\n",
            "       Bin_3     0.6842    0.6190    0.6500        21\n",
            "       Bin_4     0.6111    0.5238    0.5641        21\n",
            "\n",
            "    accuracy                         0.6235        85\n",
            "   macro avg     0.6256    0.6218    0.6199        85\n",
            "weighted avg     0.6254    0.6235    0.6206        85\n",
            "\n",
            "Confusion Matrix (rows=truth, cols=pred) shape (4, 4)\n",
            "\n",
            "SVC Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Bin_1     0.5588    0.8636    0.6786        22\n",
            "       Bin_2     0.6250    0.4762    0.5405        21\n",
            "       Bin_3     0.5882    0.4762    0.5263        21\n",
            "       Bin_4     0.3889    0.3333    0.3590        21\n",
            "\n",
            "    accuracy                         0.5412        85\n",
            "   macro avg     0.5402    0.5373    0.5261        85\n",
            "weighted avg     0.5405    0.5412    0.5279        85\n",
            "\n",
            "Confusion Matrix (rows=truth, cols=pred) shape (4, 4)\n",
            "\n",
            "KNeighbors Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Bin_1     0.5862    0.7727    0.6667        22\n",
            "       Bin_2     0.5833    0.6667    0.6222        21\n",
            "       Bin_3     0.5882    0.4762    0.5263        21\n",
            "       Bin_4     0.5333    0.3810    0.4444        21\n",
            "\n",
            "    accuracy                         0.5765        85\n",
            "   macro avg     0.5728    0.5741    0.5649        85\n",
            "weighted avg     0.5729    0.5765    0.5661        85\n",
            "\n",
            "Confusion Matrix (rows=truth, cols=pred) shape (4, 4)\n",
            "  ERROR training GaussianNB: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n",
            "\n",
            "=== OPTIONAL: 5-fold CV scores (R^2) for top regression models ===\n",
            "\n",
            "Script finished. You can extend this script to do hyperparameter tuning (GridSearchCV), feature importance plotting, or saving models with joblib.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Car Price Prediction - Regression + Classification (binned price)\n",
        "Loads: /mnt/data/a52be7b2-b050-473c-b69e-56bd3e3f992d.csv\n",
        "\n",
        "Outputs:\n",
        " - Regression metrics for multiple regressors\n",
        " - Classification reports (precision/recall/f1) after binning price into categories\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer, LabelEncoder\n",
        "\n",
        "# Regression models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Classification models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---------- Utilities to parse messy columns ----------\n",
        "def extract_first_number(s):\n",
        "    \"\"\"Extract first float/integer from a string, return np.nan if none\"\"\"\n",
        "    if pd.isnull(s):\n",
        "        return np.nan\n",
        "    s = str(s)\n",
        "    m = re.search(r'[\\d]+(?:\\.\\d+)?', s.replace(',', ''))\n",
        "    return float(m.group()) if m else np.nan\n",
        "\n",
        "def parse_engine_capacity(val):\n",
        "    \"\"\"Handle values like '1998 cc', '2.0L', '75 kWh' -> numeric (we'll keep kWh as numeric too)\"\"\"\n",
        "    if pd.isnull(val):\n",
        "        return np.nan\n",
        "    s = str(val).lower()\n",
        "    # if contains 'kwh' treat as numeric battery size\n",
        "    if 'kwh' in s:\n",
        "        return extract_first_number(s)  # battery size in kWh\n",
        "    # liters -> convert to cc if necessary\n",
        "    if 'l' in s and not 'cc' in s:\n",
        "        n = extract_first_number(s)\n",
        "        # if value < 30 assume liters\n",
        "        if n is not None and n < 30:\n",
        "            return n * 1000.0  # liters -> cc\n",
        "    # default: extract number (often in cc)\n",
        "    return extract_first_number(s)\n",
        "\n",
        "def parse_horsepower(val):\n",
        "    \"\"\"Extract horsepower numeric (hp)\"\"\"\n",
        "    return extract_first_number(val)\n",
        "\n",
        "def parse_torque(val):\n",
        "    \"\"\"Extract torque numeric (assumes Nm)\"\"\"\n",
        "    return extract_first_number(val)\n",
        "\n",
        "def parse_top_speed(val):\n",
        "    \"\"\"Extract top speed numeric (km/h)\"\"\"\n",
        "    return extract_first_number(val)\n",
        "\n",
        "def parse_acceleration(val):\n",
        "    \"\"\"Extract 0-100 km/h seconds (numeric)\"\"\"\n",
        "    return extract_first_number(val)\n",
        "\n",
        "def find_price_col(df):\n",
        "    \"\"\"Attempt to find price column by name containing 'price' or '₹' or 'inr' etc.\"\"\"\n",
        "    for c in df.columns:\n",
        "        if 'price' in c.lower() or '₹' in c or 'inr' in c.lower() or 'rs' in c.lower():\n",
        "            return c\n",
        "    # fallback: last column\n",
        "    return df.columns[-1]\n",
        "\n",
        "# ---------- Load dataset ----------\n",
        "csv_path = \"/content/Cars Datasets 2025.csv\"\n",
        "df = pd.read_csv(csv_path, encoding='latin-1')\n",
        "\n",
        "print(\"Dataset loaded. Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# ---------- Normalize column names (helpful) ----------\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Find likely column names (flexible)\n",
        "price_col = find_price_col(df)\n",
        "print(\"Detected price column:\", price_col)\n",
        "\n",
        "# Example possible column name patterns\n",
        "# company name, car name, engine type/config, engine capacity, horsepower, torque, top speed, acceleration, fuel type, seating capacity\n",
        "# We'll attempt to map automatically where possible:\n",
        "col_map = {}\n",
        "cols_lower = {c.lower(): c for c in df.columns}\n",
        "\n",
        "def find_col_by_keywords(keywords):\n",
        "    keys = keywords if isinstance(keywords, list) else [keywords]\n",
        "    for k in keys:\n",
        "        for col_lower, orig in cols_lower.items():\n",
        "            if k in col_lower:\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "col_map['company'] = find_col_by_keywords(['company', 'maker', 'manufacturer', 'brand'])\n",
        "col_map['car_name'] = find_col_by_keywords(['car name', 'model', 'car'])\n",
        "col_map['engine_type'] = find_col_by_keywords(['engine type', 'engine config', 'configuration', 'engine'])\n",
        "col_map['capacity'] = find_col_by_keywords(['capacity', 'cc', 'kwh', 'battery', 'displacement'])\n",
        "col_map['horsepower'] = find_col_by_keywords(['horsepower', 'hp', 'bhp'])\n",
        "col_map['torque'] = find_col_by_keywords(['torque', 'nm'])\n",
        "col_map['top_speed'] = find_col_by_keywords(['top speed', 'top_speed', 'topspeed', 'km/h', 'kmh'])\n",
        "col_map['acceleration'] = find_col_by_keywords(['0-100', '0–100', '0 to 100', 'acceleration', '0-60', '0–60'])\n",
        "col_map['fuel_type'] = find_col_by_keywords(['fuel', 'fuel type', 'fuel_type'])\n",
        "col_map['seating'] = find_col_by_keywords(['seat', 'seating', 'capacity'])\n",
        "\n",
        "# Print mapping for user awareness\n",
        "print(\"\\nAuto-detected column mapping:\")\n",
        "for k, v in col_map.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "# ---------- Create working dataframe with selected columns ----------\n",
        "# Keep company, engine_type, capacity, horsepower, torque, top_speed, acceleration, fuel_type, seating, price\n",
        "working_cols = []\n",
        "for key in ['company', 'engine_type', 'capacity', 'horsepower', 'torque', 'top_speed', 'acceleration', 'fuel_type', 'seating', 'car_name']:\n",
        "    if col_map.get(key):\n",
        "        working_cols.append(col_map[key])\n",
        "# ensure price included\n",
        "if price_col not in working_cols:\n",
        "    working_cols.append(price_col)\n",
        "\n",
        "# If nothing detected, use all columns as fallback\n",
        "if len(working_cols) < 3:\n",
        "    print(\"Few columns auto-detected. Using all original columns as fallback.\")\n",
        "    working_df = df.copy()\n",
        "else:\n",
        "    working_df = df[working_cols].copy()\n",
        "\n",
        "# Rename columns to friendly names\n",
        "rename_map = {}\n",
        "for key in ['company','car_name','engine_type','capacity','horsepower','torque','top_speed','acceleration','fuel_type','seating']:\n",
        "    if col_map.get(key):\n",
        "        rename_map[col_map[key]] = key\n",
        "rename_map[price_col] = 'price'\n",
        "working_df = working_df.rename(columns=rename_map)\n",
        "print(\"\\nWorking dataframe columns after rename:\", working_df.columns.tolist())\n",
        "\n",
        "# ---------- Feature parsing ----------\n",
        "# Parse numeric fields\n",
        "if 'capacity' in working_df.columns:\n",
        "    working_df['capacity_num'] = working_df['capacity'].apply(parse_engine_capacity)\n",
        "else:\n",
        "    working_df['capacity_num'] = np.nan\n",
        "\n",
        "if 'horsepower' in working_df.columns:\n",
        "    working_df['hp_num'] = working_df['horsepower'].apply(parse_horsepower)\n",
        "else:\n",
        "    working_df['hp_num'] = np.nan\n",
        "\n",
        "if 'torque' in working_df.columns:\n",
        "    working_df['torque_num'] = working_df['torque'].apply(parse_torque)\n",
        "else:\n",
        "    working_df['torque_num'] = np.nan\n",
        "\n",
        "if 'top_speed' in working_df.columns:\n",
        "    working_df['topspeed_num'] = working_df['top_speed'].apply(parse_top_speed)\n",
        "else:\n",
        "    working_df['topspeed_num'] = np.nan\n",
        "\n",
        "if 'acceleration' in working_df.columns:\n",
        "    working_df['accel_num'] = working_df['acceleration'].apply(parse_acceleration)\n",
        "else:\n",
        "    working_df['accel_num'] = np.nan\n",
        "\n",
        "# seating numeric\n",
        "if 'seating' in working_df.columns:\n",
        "    working_df['seating_num'] = working_df['seating'].apply(extract_first_number)\n",
        "else:\n",
        "    working_df['seating_num'] = np.nan\n",
        "\n",
        "# Price: extract numeric (if ranges like '20-25L' or '₹ 20,00,000' handle heuristically)\n",
        "def parse_price(val):\n",
        "    if pd.isnull(val):\n",
        "        return np.nan\n",
        "    s = str(val).lower().replace(',', '').replace('inr', '').replace('rs.', '').replace('₹','').strip()\n",
        "    # handle ranges like '20-25 lakh' or '20-25 lakh' or '20-25L'\n",
        "    # try to extract numbers and multipliers\n",
        "    nums = re.findall(r'[\\d]+(?:\\.\\d+)?', s)\n",
        "    if not nums:\n",
        "        return np.nan\n",
        "    nums = [float(x) for x in nums]\n",
        "    # infer multiplier words\n",
        "    multiplier = 1.0\n",
        "    if 'lakh' in s or 'lac' in s or 'l' in s and 'k' not in s:\n",
        "        # interpret as lakhs -> convert to rupees (but keeping numeric unit is fine)\n",
        "        # We'll convert everything to a common currency unit: assume numbers are in lakhs or in thousands?\n",
        "        # Simpler approach: if numbers < 100 and 'lakh' in s assume it's lakhs -> multiply by 100000\n",
        "        if any(x < 100 for x in nums):\n",
        "            multiplier = 100000.0\n",
        "    if 'crore' in s:\n",
        "        multiplier = 10000000.0\n",
        "    if 'k' in s and 'km' not in s:\n",
        "        multiplier = 1000.0\n",
        "    # take average if range\n",
        "    val = np.mean(nums) * multiplier\n",
        "    return val\n",
        "\n",
        "working_df['price_num'] = working_df['price'].apply(parse_price)\n",
        "\n",
        "# If price is still NaN (maybe already numeric), attempt direct cast\n",
        "if working_df['price_num'].isna().sum() > 0:\n",
        "    try:\n",
        "        working_df['price_num'] = working_df['price_num'].fillna(pd.to_numeric(working_df['price'], errors='coerce'))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Drop rows without price\n",
        "before = working_df.shape[0]\n",
        "working_df = working_df.dropna(subset=['price_num']).reset_index(drop=True)\n",
        "after = working_df.shape[0]\n",
        "print(f\"\\nDropped {before-after} rows without parsable price. Remaining: {after}\")\n",
        "\n",
        "# ---------- Select features for modeling ----------\n",
        "# Choose categorical features: company, engine_type, fuel_type, maybe car_name (but can be high-cardinality)\n",
        "cat_features = [c for c in ['company', 'engine_type', 'fuel_type', 'car_name'] if c in working_df.columns]\n",
        "num_features = ['capacity_num', 'hp_num', 'torque_num', 'topspeed_num', 'accel_num', 'seating_num']\n",
        "\n",
        "# Ensure numeric columns exist\n",
        "num_features = [c for c in num_features if c in working_df.columns]\n",
        "\n",
        "print(\"\\nCategorical features:\", cat_features)\n",
        "print(\"Numeric features:\", num_features)\n",
        "\n",
        "# Create final feature DataFrame\n",
        "X = working_df[cat_features + num_features].copy()\n",
        "y_reg = working_df['price_num'].astype(float).copy()\n",
        "\n",
        "# Simple stats\n",
        "print(\"\\nTarget price stats (num):\")\n",
        "print(y_reg.describe().apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x))\n",
        "\n",
        "# ---------- Split data ----------\n",
        "X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---------- Preprocessing pipelines ----------\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, num_features),\n",
        "    ('cat', categorical_transformer, cat_features)\n",
        "], remainder='drop')\n",
        "\n",
        "# ---------- Regression models ----------\n",
        "regressors = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(alpha=1.0),\n",
        "    'Lasso': Lasso(alpha=0.01, max_iter=5000),\n",
        "    'SVR': SVR(kernel='rbf', C=1.0, gamma='scale'),\n",
        "    'KNNRegressor': KNeighborsRegressor(n_neighbors=5),\n",
        "    'DecisionTreeRegressor': DecisionTreeRegressor(max_depth=6, random_state=42),\n",
        "    'RandomForestRegressor': RandomForestRegressor(n_estimators=200, max_depth=12, random_state=42, n_jobs=-1),\n",
        "    'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "}\n",
        "\n",
        "def eval_regressor(name, model, X_train, X_test, y_train, y_test):\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('regressor', model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    preds = pipe.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"  MAE  : {mae:,.2f}\")\n",
        "    print(f\"  RMSE : {rmse:,.2f}\")\n",
        "    print(f\"  R^2  : {r2:.4f}\")\n",
        "    return pipe, preds\n",
        "\n",
        "print(\"\\n=== REGRESSION: Training and evaluating models ===\")\n",
        "regression_results = {}\n",
        "for name, model in regressors.items():\n",
        "    try:\n",
        "        pipe, preds = eval_regressor(name, model, X_train, X_test, y_train_reg, y_test_reg)\n",
        "        regression_results[name] = {'pipeline': pipe, 'preds': preds}\n",
        "    except Exception as e:\n",
        "        print(f\"  ERROR training {name}: {e}\")\n",
        "\n",
        "# ---------- Classification: bin price into categories and run classifiers ----------\n",
        "# We'll create price categories (e.g., 4 bins: Low / Mid / High / Luxury) using quantiles by default\n",
        "n_bins = 4\n",
        "# KBinsDiscretizer can create bins but we'll use quantiles manually for labeling clarity\n",
        "bins = np.quantile(y_reg, np.linspace(0, 1, n_bins + 1))\n",
        "# Ensure unique edges\n",
        "bins = np.unique(bins)\n",
        "print(\"\\nPrice bin edges (numeric):\", bins)\n",
        "\n",
        "# Create category labels\n",
        "labels = [f\"Bin_{i+1}\" for i in range(len(bins)-1)]\n",
        "working_df['price_bin'] = pd.cut(working_df['price_num'], bins=bins, labels=labels, include_lowest=True)\n",
        "print(\"\\nPrice bin counts:\")\n",
        "print(working_df['price_bin'].value_counts())\n",
        "\n",
        "# Use same X but align y_class with X rows (we already had X aligned earlier)\n",
        "y_class_all = working_df['price_bin'].astype(str)\n",
        "# Rebuild X_all to ensure alignment\n",
        "X_all = working_df[cat_features + num_features].copy()\n",
        "\n",
        "# Split for classification (stratify by bins to preserve distribution)\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_all, y_class_all, test_size=0.2, random_state=42, stratify=y_class_all)\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=2000),\n",
        "    'DecisionTree': DecisionTreeClassifier(max_depth=8, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=200, max_depth=12, random_state=42, n_jobs=-1),\n",
        "    'GradientBoosting': GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42),\n",
        "    'SVC': SVC(kernel='rbf', probability=True),\n",
        "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
        "    'GaussianNB': GaussianNB()\n",
        "}\n",
        "\n",
        "def eval_classifier(name, clf, X_train, X_test, y_train, y_test):\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('clf', clf)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    ypred = pipe.predict(X_test)\n",
        "    print(f\"\\n{name} Classification Report:\")\n",
        "    print(classification_report(y_test, ypred, digits=4))\n",
        "    cm = confusion_matrix(y_test, ypred, labels=np.unique(y_test))\n",
        "    print(f\"Confusion Matrix (rows=truth, cols=pred) shape {cm.shape}\")\n",
        "    return pipe, ypred\n",
        "\n",
        "print(\"\\n=== CLASSIFICATION: Training and printing classification reports ===\")\n",
        "classification_results = {}\n",
        "for name, clf in classifiers.items():\n",
        "    try:\n",
        "        pipe, ypred = eval_classifier(name, clf, Xc_train, Xc_test, yc_train, yc_test)\n",
        "        classification_results[name] = {'pipeline': pipe, 'ypred': ypred}\n",
        "    except Exception as e:\n",
        "        print(f\"  ERROR training {name}: {e}\")\n",
        "\n",
        "# ---------- Quick cross-validation summary (optional) ----------\n",
        "print(\"\\n=== OPTIONAL: 5-fold CV scores (R^2) for top regression models ===\")\n",
        "from sklearn.model_selection import cross_val_score\n",
        "for name in ['RandomForestRegressor', 'GradientBoostingRegressor', 'Ridge']:\n",
        "    if name in regression_results:\n",
        "        model_pipeline = regression_results[name]['pipeline']\n",
        "        scores = cross_val_score(model_pipeline, X, y_reg, cv=5, scoring='r2', n_jobs=-1)\n",
        "        print(f\"{name} CV R^2 mean: {scores.mean():.4f}, std: {scores.std():.4f}\")\n",
        "\n",
        "print(\"\\nScript finished. You can extend this script to do hyperparameter tuning (GridSearchCV), feature importance plotting, or saving models with joblib.\")"
      ]
    }
  ]
}